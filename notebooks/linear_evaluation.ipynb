{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fs01/home/pwilson/projects/ibot\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/pwilson/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from main_ibot import build_models\n",
    "conf = OmegaConf.load(\"conf_new/main_ibot.yaml\")\n",
    "\n",
    "student, teacher = build_models(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Identity()\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "teacher.backbone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from torchvision.datasets import ImageFolder\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "env = os.environ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, dataloader\n",
    "from torch.utils.data.distributed import Dataset\n",
    "from warnings import warn \n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from src.transform import NormalizeToTensor\n",
    "from torchvision import transforms as T \n",
    "\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    NormalizeToTensor()\n",
    "])\n",
    "\n",
    "train_ds = ImageFolder(os.path.join(env['NCT_PATCHES'], 'train'), transform=transform, target_transform=lambda l: torch.tensor(l).long())\n",
    "train_loader = DataLoader(train_ds, batch_size=8)\n",
    "val_ds = ImageFolder(os.path.join(env['NCT_PATCHES'], 'val'), transform=transform, target_transform=lambda l: torch.tensor(l).long())\n",
    "val_loader = DataLoader(val_ds)\n",
    "im = next(iter(train_loader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 197, 384])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(im.shape)\n",
    "teacher.backbone(im, return_all_tokens=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher.backbone.masked_im_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('self', 'x', 'return_all_tokens', 'mask', 'blk')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher.backbone.forward.__code__.co_varnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Identity()\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 0:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 0:   0%|          | 0/250 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [8, 2], got [8]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m teacher\u001b[38;5;241m.\u001b[39mbackbone\n\u001b[1;32m      7\u001b[0m ft \u001b[38;5;241m=\u001b[39m FineTuning(in_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m384\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m ft\u001b[38;5;241m.\u001b[39mrun(teacher\u001b[38;5;241m.\u001b[39mbackbone, train_loader, val_loader)\n",
      "File \u001b[0;32m/fs01/home/pwilson/projects/ibot/src/ssl_evaluation.py:201\u001b[0m, in \u001b[0;36mFineTuning.run\u001b[0;34m(self, backbone, train_loader, val_loader, test_loader)\u001b[0m\n\u001b[1;32m    198\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs): \n\u001b[0;32m--> 201\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch(\n\u001b[1;32m    202\u001b[0m         model, train_loader, criterion, opt, sched, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m     )\n\u001b[1;32m    204\u001b[0m     val_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch(\n\u001b[1;32m    205\u001b[0m         model, val_loader, criterion, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m    206\u001b[0m     )\n\u001b[1;32m    207\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/fs01/home/pwilson/projects/ibot/src/ssl_evaluation.py:237\u001b[0m, in \u001b[0;36mFineTuning._epoch\u001b[0;34m(self, model, loader, criterion, opt, sched, desc)\u001b[0m\n\u001b[1;32m    234\u001b[0m step_logs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    236\u001b[0m score \u001b[38;5;241m=\u001b[39m model(image)\n\u001b[0;32m--> 237\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(score, label)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training: \n\u001b[1;32m    240\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mcross_entropy(\u001b[38;5;28minput\u001b[39m, target, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m   1180\u001b[0m                            ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction,\n\u001b[1;32m   1181\u001b[0m                            label_smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_smoothing)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3052\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mcross_entropy_loss(\u001b[38;5;28minput\u001b[39m, target, weight, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [8, 2], got [8]"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "from src.ssl_evaluation import FineTuning\n",
    "\n",
    "teacher.backbone\n",
    "\n",
    "ft = FineTuning(in_features=384)\n",
    "ft.run(teacher.backbone, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8192])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = next(iter(train_loader))\n",
    "student.backbone.masked_im_modeling = False\n",
    "student.backbone(image)\n",
    "student([image])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:19<00:00, 12.94it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 885/885 [00:14<00:00, 61.81it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.distributed\n",
    "from tqdm import tqdm \n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np \n",
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "import wandb \n",
    "\n",
    "\n",
    "class IBOTModule(nn.Module):\n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor: \n",
    "        \"\"\"Run forward pass on the model. \n",
    "        \n",
    "        Args: \n",
    "            x: Input tensor. should be an image tensor of shape B, C, H, W\n",
    "\n",
    "        Returns:\n",
    "            Output tensor. This will be a tensor of shape B, N, C, where B is the batch size \n",
    "            and N is the number of tokens (one token per patch plus one for the cls token). \n",
    "            cls token is the 0'th token.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "def compute_binary_classification_metrics(y_score, y_true, log_images=False):\n",
    "    \"\"\"Calculate metrics for the cancer classification problem.\n",
    "\n",
    "    Args:\n",
    "        y_score (np.array or torch.Tensor) - A column vector of predicted probabilities for\n",
    "            cancer (1) or benign(0)\n",
    "        y_true (np.array or torch.Tensor) - A column vector of true labels for cancer (1) or benign(0)\n",
    "        log_images (bool) - If True, log images of the histogram of predictions and the ROC curve to\n",
    "            wandb. Default is False.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(y_score, torch.Tensor):\n",
    "        y_score = y_score.cpu().numpy()\n",
    "    if isinstance(y_true, torch.Tensor):\n",
    "        y_true = y_true.cpu().numpy()\n",
    "\n",
    "    # augmentations can cause NaNs\n",
    "    nanvalues = np.isnan(y_score)\n",
    "    y_score = y_score[~nanvalues]\n",
    "    y_true = y_true[~nanvalues]\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    try: \n",
    "        metrics[\"auc\"] = roc_auc_score(y_true, y_score)\n",
    "    except ValueError:\n",
    "        warnings.warn(\"ROC AUC score could not be calculated. Setting to 0.5\")\n",
    "        metrics[\"auc\"] = 0.5\n",
    "\n",
    "    # find the sensitivity at fixed specificities\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "\n",
    "    for specificity in [0.20, 0.40, 0.60, 0.80]:\n",
    "        sensitivity = tpr[np.argmax(fpr > 1 - specificity)]\n",
    "        metrics[f\"sens_at_{specificity*100:.0f}_spe\"] = sensitivity\n",
    "\n",
    "    # choose the threshold that maximizes balanced accuracy\n",
    "    best_threshold = thresholds[np.argmax(tpr - fpr)]\n",
    "    metrics[\"f1\"] = f1_score(y_true, y_score > best_threshold)\n",
    "\n",
    "    if log_images:\n",
    "        plt.hist(y_score[y_true == 0], bins=100, alpha=0.5, density=True)\n",
    "        plt.hist(y_score[y_true == 1], bins=100, alpha=0.5, density=True)\n",
    "        plt.legend([\"Benign\", \"Cancer\"])\n",
    "        plt.xlabel(f\"Probability of cancer\")\n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.title(f\"AUC: {metrics['auc']:.3f}\")\n",
    "        metrics[\"histogram\"] = wandb.Image(plt, caption=\"Histogram of core predictions\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlabel(\"False positive rate\")\n",
    "        plt.ylabel(\"True positive rate\")\n",
    "        plt.title(\"ROC curve\")\n",
    "        metrics[\"roc_curve\"] = wandb.Image(plt, caption=\"ROC curve\")\n",
    "        plt.close()\n",
    "\n",
    "    metrics['balanced_accuracy'] = balanced_accuracy_score(y_true, y_score > best_threshold)\n",
    "    metrics['auprc'] = average_precision_score(y_true, y_score)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "class LinearProbing: \n",
    "    def __init__(self, train_loader, val_loader, device):\n",
    "        self.train_loader = train_loader \n",
    "        self.val_loader = val_loader \n",
    "        self.device = device\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _extract_features(self, loader, model: IBOTModule, desc: str = None): \n",
    "        model.eval().to(self.device)\n",
    "\n",
    "        features = []\n",
    "        labels = []\n",
    "        for (image, label) in tqdm(loader, desc=desc): \n",
    "            image = image.to(self.device)\n",
    "            label = label.to(self.device)\n",
    "            outputs = model(image)\n",
    "            cls = outputs[:, 0, :]\n",
    "            cls = concat_all_gather(cls)\n",
    "            label = concat_all_gather(label)\n",
    "            features.append(cls)\n",
    "            labels.append(label)\n",
    "\n",
    "        features = torch.cat(features, dim=0)\n",
    "        labels = torch.cat(labels, dim=0)\n",
    "\n",
    "        return features, labels \n",
    "\n",
    "    def run_probing(self, model: IBOTModule):\n",
    "        \"\"\"Returns the metrics for the linear probing task.\"\"\"\n",
    "\n",
    "        metrics = {}\n",
    "\n",
    "        X_train, y_train = self._extract_features(self.train_loader, model)\n",
    "        X_train = X_train.cpu().numpy()\n",
    "        y_train = y_train.cpu().numpy()\n",
    "        X_val, y_val = self._extract_features(self.val_loader, model)\n",
    "        X_val = X_val.cpu().numpy()\n",
    "        y_val = y_val.cpu().numpy()\n",
    "\n",
    "        if torch.distributed.is_initialized(): \n",
    "            if torch.distributed.get_rank() != 0: \n",
    "                return \n",
    "\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        clf = LogisticRegression(max_iter=5000, class_weight='balanced')\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_train = clf.predict_proba(X_train)[:, -1]\n",
    "        y_pred_val = clf.predict_proba(X_val)[:, -1]\n",
    "\n",
    "        metrics['train'] = compute_binary_classification_metrics(y_pred_train, y_train)\n",
    "        metrics['val'] = compute_binary_classification_metrics(y_pred_val, y_val)\n",
    " \n",
    "        return metrics\n",
    "\n",
    "\n",
    "lp = LinearProbing(train_loader, val_loader, device='cuda')\n",
    "metrics = lp.run_probing(student.backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpfrwilson\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/ssd004/scratch/pwilson/wandb/run-20240530_105003-oj3i9mwa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pfrwilson/iBOT/runs/oj3i9mwa' target=\"_blank\">worthy-cloud-71</a></strong> to <a href='https://wandb.ai/pfrwilson/iBOT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pfrwilson/iBOT' target=\"_blank\">https://wandb.ai/pfrwilson/iBOT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pfrwilson/iBOT/runs/oj3i9mwa' target=\"_blank\">https://wandb.ai/pfrwilson/iBOT/runs/oj3i9mwa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"ibot\", job_type=\"linear-probing\")\n",
    "wandb.log(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1998, 2048])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1426, device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape\n",
    "\n",
    "labels.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
